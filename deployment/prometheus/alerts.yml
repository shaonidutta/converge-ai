# Prometheus Alert Rules for ConvergeAI

groups:
  # API Health Alerts
  - name: api_health
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status_code=~"5.."}[5m]))
            /
            sum(rate(http_requests_total[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
      
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
          ) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High API latency detected"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.endpoint }}"
      
      - alert: APIDown
        expr: up{job="convergeai-backend"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "ConvergeAI API is down"
          description: "The API has been down for more than 1 minute"

  # Agent Performance Alerts
  - name: agent_performance
    interval: 30s
    rules:
      - alert: HighAgentErrorRate
        expr: |
          (
            sum(rate(agent_errors_total[5m])) by (agent_name)
            /
            sum(rate(agent_executions_total[5m])) by (agent_name)
          ) > 0.10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High agent error rate"
          description: "{{ $labels.agent_name }} error rate is {{ $value | humanizePercentage }}"
      
      - alert: SlowAgentExecution
        expr: |
          histogram_quantile(0.95,
            sum(rate(agent_execution_duration_seconds_bucket[5m])) by (le, agent_name)
          ) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow agent execution"
          description: "{{ $labels.agent_name }} 95th percentile is {{ $value }}s"

  # LLM Usage Alerts
  - name: llm_usage
    interval: 30s
    rules:
      - alert: HighLLMErrorRate
        expr: |
          (
            sum(rate(llm_errors_total[5m]))
            /
            sum(rate(llm_requests_total[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High LLM error rate"
          description: "LLM error rate is {{ $value | humanizePercentage }}"
      
      - alert: HighTokenUsage
        expr: rate(llm_tokens_used_total[1h]) > 1000000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High LLM token usage"
          description: "Token usage rate is {{ $value }} tokens/sec"

  # Database Alerts
  - name: database
    interval: 30s
    rules:
      - alert: SlowDatabaseQueries
        expr: |
          histogram_quantile(0.95,
            sum(rate(db_query_duration_seconds_bucket[5m])) by (le, operation)
          ) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries"
          description: "{{ $labels.operation }} 95th percentile is {{ $value }}s"
      
      - alert: HighDatabaseConnections
        expr: db_connections_active > 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connection count"
          description: "Active connections: {{ $value }}"

  # RAG Performance Alerts
  - name: rag_performance
    interval: 30s
    rules:
      - alert: LowGroundingScore
        expr: |
          histogram_quantile(0.50,
            sum(rate(rag_grounding_score_bucket[5m])) by (le, agent_name)
          ) < 0.45
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low RAG grounding score"
          description: "{{ $labels.agent_name }} median grounding score is {{ $value }}"
      
      - alert: SlowRAGRetrieval
        expr: |
          histogram_quantile(0.95,
            sum(rate(rag_retrieval_duration_seconds_bucket[5m])) by (le, namespace)
          ) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow RAG retrieval"
          description: "{{ $labels.namespace }} 95th percentile is {{ $value }}s"

  # Business Metrics Alerts
  - name: business_metrics
    interval: 1m
    rules:
      - alert: HighComplaintRate
        expr: |
          (
            sum(rate(complaints_created_total[1h]))
            /
            sum(rate(bookings_created_total[1h]))
          ) > 0.20
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "High complaint rate"
          description: "Complaint rate is {{ $value | humanizePercentage }} of bookings"

